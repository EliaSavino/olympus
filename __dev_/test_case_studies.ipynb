{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ae80666",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88eb67ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import olympus\n",
    "from olympus.datasets import Dataset\n",
    "from olympus.evaluators import Evaluator\n",
    "from olympus.emulators import Emulator\n",
    "from olympus.campaigns import Campaign\n",
    "from olympus.planners import Planner\n",
    "from olympus.scalarizers import Scalarizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3493f2",
   "metadata": {},
   "source": [
    "## CASE STUDY 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b67b0645",
   "metadata": {},
   "outputs": [],
   "source": [
    "cs1_datasets = ['dye_lasers']\n",
    "cs1_planners = [\n",
    "    #'RandomSearch', \n",
    "    'Genetic',\n",
    "    #'Hyperopt', \n",
    "    #'Gpyopt', \n",
    "    #'Gryffin', \n",
    "    #'Dragonfly', \n",
    "    #'Botorch',\n",
    "    #'Smac',\n",
    "    #'Hebo',\n",
    "]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd7d4aa3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TESTING Genetic ON dye_lasers ...\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'Individual' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_46469/1360675599.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     56\u001b[0m             )\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0mevaluator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Done!'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Research_Local/olympus/src/olympus/evaluators/evaluator.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, num_iter)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0;31m# get new params from planner\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplanner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecommend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplanner_observations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0memulator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameter_constriants\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"simplex\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Research_Local/olympus/src/olympus/planners/abstract_planner.py\u001b[0m in \u001b[0;36mrecommend\u001b[0;34m(self, observations, return_as)\u001b[0m\n\u001b[1;32m    136\u001b[0m         \"\"\"\n\u001b[1;32m    137\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreturn_as\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_as\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memulator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscalarizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Research_Local/olympus/src/olympus/planners/abstract_planner.py\u001b[0m in \u001b[0;36mask\u001b[0;34m(self, return_as)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_generated\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m         \u001b[0mparam_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0;31m# check that the parameters suggested are within the bounds of our param_space\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Research_Local/olympus/src/olympus/planners/planner_genetic/wrapper_deap.py\u001b[0m in \u001b[0;36m_ask\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    339\u001b[0m                                 \u001b[0;31m# keep doing this if by chance we did not do any cross-over or mutation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m                                 \u001b[0;32mwhile\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moffsprings_to_be_evaluated\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m                                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_generate_offsprings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m                 \u001b[0;31m# evaluate one offspring at a time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Research_Local/olympus/src/olympus/planners/planner_genetic/wrapper_deap.py\u001b[0m in \u001b[0;36m_generate_offsprings\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    288\u001b[0m                                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m                                         \u001b[0mLogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"  Performing cross-over operation\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"INFO\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 290\u001b[0;31m                                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoolbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchild1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchild2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    291\u001b[0m                                 \u001b[0;32mdel\u001b[0m \u001b[0mchild1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfitness\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m                                 \u001b[0;32mdel\u001b[0m \u001b[0mchild2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfitness\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Software/anaconda3/envs/olympus/lib/python3.7/site-packages/deap/tools/selection.py\u001b[0m in \u001b[0;36mselTournament\u001b[0;34m(individuals, k, tournsize, fit_attr)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \"\"\"\n\u001b[1;32m     65\u001b[0m     \u001b[0mchosen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m         \u001b[0maspirants\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselRandom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindividuals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtournsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0mchosen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maspirants\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrgetter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfit_attr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'Individual' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "for dataset_name in cs1_datasets:\n",
    "    for planner_name in cs1_planners:\n",
    "        \n",
    "        print(f'\\nTESTING {planner_name} ON {dataset_name} ...\\n')\n",
    "            \n",
    "        if dataset_name == 'dye_lasers':\n",
    "            # fully categorical, lookup table\n",
    "            dataset = Dataset(kind=dataset_name)\n",
    "\n",
    "            planner = Planner(kind=planner_name)\n",
    "            planner.set_param_space(dataset.param_space)\n",
    "\n",
    "            campaign = Campaign()\n",
    "            campaign.set_param_space(dataset.param_space)\n",
    "            campaign.set_value_space(dataset.value_space)\n",
    "            \n",
    "            scalarizer = Scalarizer(\n",
    "                kind='Chimera', \n",
    "                value_space=dataset.value_space,\n",
    "                goals=['max', 'min', 'max'],\n",
    "                tolerances=[0.5, 0.5, 0.5],\n",
    "                absolutes=[False, False, False]\n",
    "            )\n",
    "\n",
    "            evaluator = Evaluator(\n",
    "                planner=planner, \n",
    "                emulator=dataset,\n",
    "                campaign=campaign,\n",
    "                scalarizer=scalarizer,\n",
    "            )\n",
    "        \n",
    "        elif dataset_name == 'redoxmers':\n",
    "            # fully categorical, lookup table\n",
    "            dataset = Dataset(kind=dataset_name)\n",
    "\n",
    "            planner = Planner(kind=planner_name)\n",
    "            planner.set_param_space(dataset.param_space)\n",
    "\n",
    "            campaign = Campaign()\n",
    "            campaign.set_param_space(dataset.param_space)\n",
    "            campaign.set_value_space(dataset.value_space)\n",
    "            \n",
    "            scalarizer = Scalarizer(\n",
    "                kind='Chimera', \n",
    "                value_space=dataset.value_space,\n",
    "                goals=['min', 'min', 'min'],\n",
    "                tolerances=[0.5, 0.5, 0.5],\n",
    "                absolutes=[False, False, False]\n",
    "            )\n",
    "\n",
    "            evaluator = Evaluator(\n",
    "                planner=planner, \n",
    "                emulator=dataset,\n",
    "                campaign=campaign,\n",
    "                scalarizer=scalarizer,\n",
    "            )\n",
    "            \n",
    "        evaluator.optimize(num_iter=15)\n",
    "        \n",
    "        print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1fffb05",
   "metadata": {},
   "outputs": [],
   "source": [
    "campaign.observations.get_params()\n",
    "campaign.observations.get_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c27c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "campaign.scalarized_observations.get_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2759f8e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b538ac47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2fca5412",
   "metadata": {},
   "source": [
    "## CASE STUDY 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7cf02d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------\n",
    "# SUZUKI MIYAURA\n",
    "#----------------\n",
    "\n",
    "#suzuki_datasets = ['suzuki', 'suzuki_i', 'suzuki_ii', 'suzuki_iii', 'suzuki_iv', 'suzuki_edbo']\n",
    "suzuki_datasets = ['suzuki_i', 'suzuki_ii', 'suzuki_iii', 'suzuki_iv'] #['suzuki_edbo']\n",
    "\n",
    "suzuki_planners = [\n",
    "    #'RandomSearch', \n",
    "    'Genetic',\n",
    "    #'Hyperopt', \n",
    "    #'Gpyopt', \n",
    "    #'Gryffin', \n",
    "    #'Dragonfly', \n",
    "    #'Botorch',\n",
    "    #'Smac',\n",
    "    #'Hebo',\n",
    "]  \n",
    "#suzuki_planners = ['RandomSearch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "182aaff3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TESTING Genetic ON suzuki_i ...\n",
      "\n",
      "\u001b[0;37m[INFO] Loading emulator using a BayesNeuralNet model for the dataset suzuki_i...\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/riley/Software/anaconda3/envs/olympus/lib/python3.7/site-packages/tensorflow_probability/python/layers/util.py:102: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use the `layer.add_weight()` method instead.\n",
      "  trainable=trainable)\n",
      "/home/riley/Software/anaconda3/envs/olympus/lib/python3.7/site-packages/tensorflow_probability/python/layers/util.py:112: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use the `layer.add_weight()` method instead.\n",
      "  trainable=trainable)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "\n",
      "TESTING Genetic ON suzuki_ii ...\n",
      "\n",
      "\u001b[0;37m[INFO] Loading emulator using a BayesNeuralNet model for the dataset suzuki_ii...\n",
      "\u001b[0mDone!\n",
      "\n",
      "TESTING Genetic ON suzuki_iii ...\n",
      "\n",
      "\u001b[0;37m[INFO] Loading emulator using a BayesNeuralNet model for the dataset suzuki_iii...\n",
      "\u001b[0mDone!\n",
      "\n",
      "TESTING Genetic ON suzuki_iv ...\n",
      "\n",
      "\u001b[0;37m[INFO] Loading emulator using a BayesNeuralNet model for the dataset suzuki_iv...\n",
      "\u001b[0mDone!\n"
     ]
    }
   ],
   "source": [
    "for dataset_name in suzuki_datasets:\n",
    "    for planner_name in suzuki_planners:\n",
    "        \n",
    "        print(f'\\nTESTING {planner_name} ON {dataset_name} ...\\n')\n",
    "        \n",
    "        if dataset_name == 'suzuki': \n",
    "            \n",
    "            # fully continuous, emulated dataset\n",
    "            emulator = Emulator(dataset=dataset_name, model='BayesNeuralNet')\n",
    "            planner = Planner(kind=planner_name)\n",
    "            planner.set_param_space(emulator.param_space)\n",
    "\n",
    "            campaign = Campaign()\n",
    "            campaign.set_param_space(emulator.param_space)\n",
    "            campaign.set_value_space(emulator.value_space)\n",
    "\n",
    "            evaluator = Evaluator(\n",
    "                planner=planner, \n",
    "                emulator=emulator,\n",
    "                campaign=campaign,\n",
    "            )\n",
    "            \n",
    "        elif dataset_name == 'suzuki_edbo':\n",
    "            \n",
    "            # fully categorical, lookup table\n",
    "            dataset = Dataset(kind=dataset_name)\n",
    "\n",
    "            planner = Planner(kind=planner_name)\n",
    "            planner.set_param_space(dataset.param_space)\n",
    "\n",
    "            campaign = Campaign()\n",
    "            campaign.set_param_space(dataset.param_space)\n",
    "            campaign.set_value_space(dataset.value_space)\n",
    "\n",
    "            evaluator = Evaluator(\n",
    "                planner=planner, \n",
    "                emulator=dataset,\n",
    "                campaign=campaign,\n",
    "            )\n",
    "            \n",
    "        elif dataset_name in ['suzuki_i', 'suzuki_ii', 'suzuki_iii', 'suzuki_iv']:\n",
    "            \n",
    "            # mixed parameter, emulator, multi-objective optimization\n",
    "            emulator = Emulator(dataset=dataset_name, model='BayesNeuralNet')\n",
    "            planner = Planner(kind=planner_name)\n",
    "            planner.set_param_space(emulator.param_space)\n",
    "\n",
    "            campaign = Campaign()\n",
    "            campaign.set_param_space(emulator.param_space)\n",
    "            campaign.set_value_space(emulator.value_space)\n",
    "            \n",
    "            scalarizer = Scalarizer(\n",
    "                kind='Chimera', \n",
    "                value_space=emulator.value_space,\n",
    "                goals=['max', 'max'],\n",
    "                tolerances=[0.9, 0.0],\n",
    "                absolutes=[False, False]\n",
    "            )\n",
    "\n",
    "            evaluator = Evaluator(\n",
    "                planner=planner, \n",
    "                emulator=emulator,\n",
    "                campaign=campaign,\n",
    "                scalarizer=scalarizer,\n",
    "            )\n",
    "        \n",
    "        evaluator.optimize(num_iter=10)\n",
    "        \n",
    "        print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec0576c",
   "metadata": {},
   "outputs": [],
   "source": [
    "campaign.observations.get_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baaff1b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b25cfb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------\n",
    "# BUCHWALD-HARTWIG\n",
    "#------------------\n",
    "\n",
    "buchwald_datasets = ['buchwald_a','buchwald_b','buchwald_c','buchwald_d','buchwald_e']\n",
    "\n",
    "buchwald_planners = [\n",
    "    #'RandomSearch', \n",
    "    'Genetic',\n",
    "    #'Hyperopt', \n",
    "    #'Gpyopt', \n",
    "    #'Gryffin', \n",
    "    #'Dragonfly', \n",
    "    #'Botorch',\n",
    "    #'Smac',\n",
    "    #'Hebo',\n",
    "] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "98e8c9f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TESTING Genetic ON buchwald_a ...\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'Individual' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_46469/1856721414.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m         )\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mevaluator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Done!'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Research_Local/olympus/src/olympus/evaluators/evaluator.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, num_iter)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0;31m# get new params from planner\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplanner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecommend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplanner_observations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0memulator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameter_constriants\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"simplex\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Research_Local/olympus/src/olympus/planners/abstract_planner.py\u001b[0m in \u001b[0;36mrecommend\u001b[0;34m(self, observations, return_as)\u001b[0m\n\u001b[1;32m    136\u001b[0m         \"\"\"\n\u001b[1;32m    137\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreturn_as\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_as\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memulator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscalarizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Research_Local/olympus/src/olympus/planners/abstract_planner.py\u001b[0m in \u001b[0;36mask\u001b[0;34m(self, return_as)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_generated\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m         \u001b[0mparam_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0;31m# check that the parameters suggested are within the bounds of our param_space\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Research_Local/olympus/src/olympus/planners/planner_genetic/wrapper_deap.py\u001b[0m in \u001b[0;36m_ask\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    339\u001b[0m                                 \u001b[0;31m# keep doing this if by chance we did not do any cross-over or mutation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m                                 \u001b[0;32mwhile\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moffsprings_to_be_evaluated\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m                                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_generate_offsprings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m                 \u001b[0;31m# evaluate one offspring at a time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Research_Local/olympus/src/olympus/planners/planner_genetic/wrapper_deap.py\u001b[0m in \u001b[0;36m_generate_offsprings\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    288\u001b[0m                                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m                                         \u001b[0mLogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"  Performing cross-over operation\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"INFO\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 290\u001b[0;31m                                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoolbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchild1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchild2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    291\u001b[0m                                 \u001b[0;32mdel\u001b[0m \u001b[0mchild1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfitness\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m                                 \u001b[0;32mdel\u001b[0m \u001b[0mchild2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfitness\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Software/anaconda3/envs/olympus/lib/python3.7/site-packages/deap/tools/selection.py\u001b[0m in \u001b[0;36mselTournament\u001b[0;34m(individuals, k, tournsize, fit_attr)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \"\"\"\n\u001b[1;32m     65\u001b[0m     \u001b[0mchosen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m         \u001b[0maspirants\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselRandom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindividuals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtournsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0mchosen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maspirants\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrgetter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfit_attr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'Individual' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "buchwald_campaigns = []\n",
    "\n",
    "for dataset_name in buchwald_datasets:\n",
    "    for planner_name in buchwald_planners:\n",
    "        \n",
    "        print(f'\\nTESTING {planner_name} ON {dataset_name} ...\\n')\n",
    "        \n",
    "        dataset = Dataset(kind=dataset_name)\n",
    "        planner = Planner(kind=planner_name)\n",
    "        planner.set_param_space(dataset.param_space)\n",
    "        \n",
    "        campaign = Campaign()\n",
    "        campaign.set_param_space(dataset.param_space)\n",
    "        campaign.set_value_space(dataset.value_space)\n",
    "        \n",
    "        evaluator = Evaluator(\n",
    "            planner=planner, \n",
    "            emulator=dataset,\n",
    "            campaign=campaign,\n",
    "        )\n",
    "        \n",
    "        evaluator.optimize(num_iter=15)\n",
    "        \n",
    "        print('Done!')\n",
    "        \n",
    "        buchwald_campaigns.append(campaign)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7b330d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6fa6946a",
   "metadata": {},
   "source": [
    "## CASE STUDY 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "403fbcb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cs3_datasets = ['dye_lasers'] #'redoxmers']\n",
    "cs3_planners = [\n",
    "    #'RandomSearch', \n",
    "    #'Genetic',\n",
    "    #'Hyperopt', \n",
    "    #'Gpyopt', \n",
    "    #'Gryffin', \n",
    "    #'Dragonfly', \n",
    "    'Botorch',\n",
    "    #'Smac',\n",
    "    #'Hebo',\n",
    "] \n",
    "cs3_scalarizers = ['Chimera', 'WeightedSum', 'Parego'] # 'ConstrainedAsf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "55aa7236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TESTING Botorch ON dye_lasers WITH Chimera ...\n",
      "\n",
      "False\n",
      "tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 1., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.]], dtype=torch.float64)\n",
      "False\n",
      "tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 1., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.]], dtype=torch.float64)\n",
      "False\n",
      "tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 1., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.]], dtype=torch.float64)\n",
      "False\n",
      "tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 1., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.]], dtype=torch.float64)\n",
      "False\n",
      "tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 1., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.]], dtype=torch.float64)\n",
      "False\n",
      "tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 1., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.]], dtype=torch.float64)\n",
      "False\n",
      "tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 1., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.]], dtype=torch.float64)\n",
      "False\n",
      "tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 1., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.]], dtype=torch.float64)\n",
      "False\n",
      "tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 1., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.]], dtype=torch.float64)\n",
      "False\n",
      "tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 1., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.]], dtype=torch.float64)\n",
      "Done!\n",
      "\n",
      "TESTING Botorch ON dye_lasers WITH WeightedSum ...\n",
      "\n",
      "False\n",
      "tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 1., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.]], dtype=torch.float64)\n",
      "False\n",
      "tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 1., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.]], dtype=torch.float64)\n",
      "False\n",
      "tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 1., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.]], dtype=torch.float64)\n",
      "False\n",
      "tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 1., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.]], dtype=torch.float64)\n",
      "False\n",
      "tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 1., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.]], dtype=torch.float64)\n",
      "False\n",
      "tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 1., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.]], dtype=torch.float64)\n",
      "False\n",
      "tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 1., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.]], dtype=torch.float64)\n",
      "False\n",
      "tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 1., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.]], dtype=torch.float64)\n",
      "False\n",
      "tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 1., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.]], dtype=torch.float64)\n",
      "False\n",
      "tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 1., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.]], dtype=torch.float64)\n",
      "Done!\n",
      "\n",
      "TESTING Botorch ON dye_lasers WITH Parego ...\n",
      "\n",
      "False\n",
      "tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 1., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.]], dtype=torch.float64)\n",
      "False\n",
      "tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 1., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.]], dtype=torch.float64)\n",
      "False\n",
      "tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 1., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.]], dtype=torch.float64)\n",
      "False\n",
      "tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 1., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.]], dtype=torch.float64)\n",
      "False\n",
      "tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 1., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.]], dtype=torch.float64)\n",
      "False\n",
      "tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 1., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.]], dtype=torch.float64)\n",
      "False\n",
      "tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 1., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.]], dtype=torch.float64)\n",
      "False\n",
      "tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 1., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.]], dtype=torch.float64)\n",
      "False\n",
      "tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 1., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.]], dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 1., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.]], dtype=torch.float64)\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "for dataset_name in cs3_datasets:\n",
    "    for planner_name in cs3_planners:\n",
    "        for scalarizer_name in cs3_scalarizers:\n",
    "        \n",
    "            print(f'\\nTESTING {planner_name} ON {dataset_name} WITH {scalarizer_name} ...\\n')\n",
    "\n",
    "            if dataset_name == 'dye_lasers':\n",
    "                # fully categorical, lookup table\n",
    "                dataset = Dataset(kind=dataset_name)\n",
    "\n",
    "                planner = Planner(kind=planner_name)\n",
    "                planner.set_param_space(dataset.param_space)\n",
    "\n",
    "                campaign = Campaign()\n",
    "                campaign.set_param_space(dataset.param_space)\n",
    "                campaign.set_value_space(dataset.value_space)\n",
    "\n",
    "                if scalarizer_name == 'Chimera':\n",
    "                    scalarizer = Scalarizer(\n",
    "                        kind='Chimera', \n",
    "                        value_space=dataset.value_space,\n",
    "                        goals=['max', 'min', 'max'],\n",
    "                        tolerances=[0.5, 0.5, 0.5],\n",
    "                        absolutes=[False, False, False]\n",
    "                    )\n",
    "                elif scalarizer_name == 'Parego':\n",
    "                    scalarizer = Scalarizer(\n",
    "                        kind='Parego', \n",
    "                        value_space=dataset.value_space,\n",
    "                        goals=['max', 'min', 'max'],\n",
    "                        rho=0.05,\n",
    "                    )\n",
    "                \n",
    "                elif scalarizer_name == 'WeightedSum':\n",
    "                    scalarizer = Scalarizer(\n",
    "                        kind='WeightedSum', \n",
    "                        value_space=dataset.value_space,\n",
    "                        goals=['max', 'min', 'max'],\n",
    "                        weights=[0.33, 0.33, 0.33],\n",
    "                    )\n",
    "                \n",
    "                elif scalarizer_name == 'ConstrainedAsf':\n",
    "                    pass\n",
    "                    # TODO: implement this! \n",
    "                    \n",
    "\n",
    "                evaluator = Evaluator(\n",
    "                    planner=planner, \n",
    "                    emulator=dataset,\n",
    "                    campaign=campaign,\n",
    "                    scalarizer=scalarizer,\n",
    "                )\n",
    "\n",
    "            elif dataset_name == 'redoxmers':\n",
    "                # fully categorical, lookup table\n",
    "                dataset = Dataset(kind=dataset_name)\n",
    "\n",
    "                planner = Planner(kind=planner_name)\n",
    "                planner.set_param_space(dataset.param_space)\n",
    "\n",
    "                campaign = Campaign()\n",
    "                campaign.set_param_space(dataset.param_space)\n",
    "                campaign.set_value_space(dataset.value_space)\n",
    "\n",
    "                if scalarizer_name == 'Chimera':\n",
    "                    scalarizer = Scalarizer(\n",
    "                        kind='Chimera', \n",
    "                        value_space=dataset.value_space,\n",
    "                        goals=['min', 'min', 'min'],\n",
    "                        tolerances=[0.5, 0.5, 0.5],\n",
    "                        absolutes=[False, False, False]\n",
    "                    )\n",
    "                elif scalarizer_name == 'Parego':\n",
    "                    scalarizer = Scalarizer(\n",
    "                        kind='Parego', \n",
    "                        value_space=dataset.value_space,\n",
    "                        goals=['min', 'min', 'min'],\n",
    "                        rho=0.05,\n",
    "                    )\n",
    "                \n",
    "                elif scalarizer_name == 'WeightedSum':\n",
    "                    scalarizer = Scalarizer(\n",
    "                        kind='WeightedSum', \n",
    "                        value_space=dataset.value_space,\n",
    "                        goals=['min', 'min', 'min'],\n",
    "                        weights=[0.33, 0.33, 0.33],\n",
    "                    )\n",
    "                \n",
    "                elif scalarizer_name == 'ConstrainedAsf':\n",
    "                    pass\n",
    "                    # TODO: implement this! \n",
    "\n",
    "                evaluator = Evaluator(\n",
    "                    planner=planner, \n",
    "                    emulator=dataset,\n",
    "                    campaign=campaign,\n",
    "                    scalarizer=scalarizer,\n",
    "                )\n",
    "\n",
    "            evaluator.optimize(num_iter=15)\n",
    "\n",
    "            print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba506ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90878652",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7f11ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "olympus",
   "language": "python",
   "name": "olympus"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
